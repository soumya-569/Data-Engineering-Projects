{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85dc7a95-2869-49af-b11f-3783ab7e7938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>\uD83D\uDCCAData Enrichment Transformations (Olist E-commerce)</h3>\n",
    "<p>Below are the key enrichment transformations applied on the raw Olist datasets to create analytics-ready, business-focused features using PySpark.</p>\n",
    "<br>\n",
    "<h4>1️⃣Profit Margin</h4>\n",
    "<ul>\n",
    "  <li><b>Goal:</b> Financial insight — estimate product/order profitability.</li>\n",
    "  <li><b>Techniques:</b> Derived columns in Spark.</li>\n",
    "  <li><b>Process:</b> profit_margin = price - (0.7 * price) - freight_value</li>\n",
    "  <li><b>Features:</b> profit_margin, margin_percent</li>\n",
    "</ul>\n",
    "<br>\n",
    "<h4>2️⃣Distance</h4>\n",
    "<ul>\n",
    "  <li><b>Goal:</b> Optimize delivery cost vs distance.</li>\n",
    "  <li><b>Techniques:</b> Haversine formula (lat/lng from geolocation).</li>\n",
    "  <li><b>Process:</b> Join customers & sellers with avg lat/lng → compute distance_km.</li>\n",
    "  <li><b>Features:</b> distance_km, freight_per_km</li>\n",
    "</ul>\n",
    "<br>\n",
    "<h4>3️⃣RFM (Recency, Frequency, Monetary)</h4>\n",
    "<ul>\n",
    "  <li><b>Goal:</b> Customer segmentation.</li>\n",
    "  <li><b>Techniques:</b> Window + aggregation.</li>\n",
    "  <li><b>Process:</b> Calculate days since last order, count of orders, total spend → rank 1–5.</li>\n",
    "  <li><b>Features:</b> recency, frequency, monetary, rfm_score</li>\n",
    "</ul>\n",
    "<br>\n",
    "<h4>4️⃣Delivery Delay</h4>\n",
    "<ul>\n",
    "  <li><b>Goal:</b> Monitor delivery performance.</li>\n",
    "  <li><b>Techniques:</b> Date difference + conditional logic.</li>\n",
    "  <li><b>Process:</b> Compare actual vs estimated delivery → classify as Late/Early/On-time.</li>\n",
    "  <li><b>Features:</b> delivery_status, delay_days</li>\n",
    "</ul>\n",
    "<br>\n",
    "<h4>5️⃣Sentiment</h4>\n",
    "<ul>\n",
    "  <li><b>Goal:</b> Measure customer satisfaction (CX).</li>\n",
    "  <li><b>Techniques:</b> NLP UDF on reviews.</li>\n",
    "  <li><b>Process:</b> Apply sentiment polarity on review_comment_message.</li>\n",
    "  <li><b>Features:</b> review_sentiment, sentiment_label</li>\n",
    "</ul>\n",
    "<br>\n",
    "<h4>6️⃣Seasonality</h4>\n",
    "<ul>\n",
    "  <li><b>Goal:</b> Identify trends and seasonality.</li>\n",
    "  <li><b>Techniques:</b> Date extraction.</li>\n",
    "  <li><b>Process:</b> Extract month, year, quarter, and holiday season flag.</li>\n",
    "  <li><b>Features:</b> month, quarter, holiday_flag</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a08ce4-ebda-4bd9-b848-2a40fe2903b1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Commence Spark Session"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('olist_ecom_anz') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3deff5eb-26ce-4f1c-98b0-38400d267c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().date().isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17cba9a0-0436-45f9-99da-004a69c352c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h4>Load Data From Amazon S3 Using Spark</h4>\n",
    "<p>Already Created External Location With S3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144164b3-15bb-4dfd-8091-f3965938df94",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest Data From S3"
    }
   },
   "outputs": [],
   "source": [
    "customer = spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load(f's3://amz-s3-databricks-conn/Bronze/{now}/olist_customers_dataset.csv')\n",
    "\n",
    "geo = spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load('s3://amz-s3-databricks-conn/Bronze/olist_geolocation_dataset.csv')\n",
    "\n",
    "order_item = spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load(f's3://amz-s3-databricks-conn/Bronze/{now}/olist_order_items_dataset.csv')\n",
    "\n",
    "pay = spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load(f's3://amz-s3-databricks-conn/Bronze/{now}/olist_order_payments_dataset.csv')\n",
    "\n",
    "reviews = spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load(f's3://amz-s3-databricks-conn/Bronze/{now}/olist_order_reviews_dataset.csv')\n",
    "\n",
    "order = spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load(f's3://amz-s3-databricks-conn/Bronze/{now}/olist_orders_dataset.csv')\n",
    "\n",
    "products= spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load(f's3://amz-s3-databricks-conn/Bronze/{now}/olist_products_dataset.csv')\n",
    "\n",
    "seller = spark.read \\\n",
    "    .format('csv') \\\n",
    "        .option('header','true') \\\n",
    "            .option('mode','PERMISSIVE') \\\n",
    "                .load(f's3://amz-s3-databricks-conn/Bronze/{now}/olist_sellers_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53169db5-e237-4d88-840e-0e3237380ff5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5362dcf3-7e2c-4d9f-b104-99a8a09006c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Cleaning The Reviews Dataframe</h3>\n",
    "<p>All the columns I have cleaned below contains wrong & misleading information</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dbc7de7-172b-43ca-bc38-cc937e214dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating Character Length Column To Check For Anomalies\n",
    "\n",
    "reviews = reviews.withColumn('review_id_c_count',char_length('review_id')).withColumn('order_id_c_count',char_length('order_id')).withColumn('review_score_c_count',char_length('review_score')).withColumn('review_creation_date_c_count',char_length('review_creation_date')).withColumn('review_answer_timestamp_c_count',char_length('review_answer_timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3749940-b974-41b6-be4d-31f6af740a88",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reviews Data Clean"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Regex Patterns and leaving only valid rows\n",
    "\n",
    "regex_pattern_review_id = r'^[0-9A-Za-z]{32,40}$'\n",
    "regex_pattern_review_score = r'[0-9]'\n",
    "regex_pattern_review_creation_date = r'^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}$'\n",
    "reviews = reviews.filter(col('review_id').rlike(regex_pattern_review_id))\n",
    "reviews = reviews.filter(col('review_score').rlike(regex_pattern_review_score))\n",
    "reviews = reviews.filter(col('review_creation_date').rlike(regex_pattern_review_creation_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58006fee-140e-4ee7-9f0b-0c159074dbcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dropping Character Length Columns\n",
    "\n",
    "reviews = reviews.drop('review_id_c_count','order_id_c_count','review_score_c_count','review_creation_date_c_count','review_answer_timestamp_c_count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e317ec-4957-47bb-af0c-fcdac8bf8286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h4>Change DataTypes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eac4d638-58bc-4e43-af89-ce559a720026",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Type Change"
    }
   },
   "outputs": [],
   "source": [
    "geo = geo.withColumns(\n",
    "    {\n",
    "        'geolocation_lat': geo.geolocation_lat.cast('float'),\n",
    "        'geolocation_lng': geo.geolocation_lng.cast('float')\n",
    "    }\n",
    ")\n",
    "\n",
    "order_item = order_item.withColumns(\n",
    "    {\n",
    "        'order_item_id':col('order_item_id').cast('int'),\n",
    "        'shipping_date':split(col('shipping_limit_date'),' ')[0].cast('date'),\n",
    "        'shipping_time':split(col('shipping_limit_date'),' ')[1],\n",
    "        'price':col('price').cast('float'),\n",
    "        'freight_value':col('freight_value').cast('float'),\n",
    "        'shipping_limit_date':to_timestamp(col('shipping_limit_date'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType())\n",
    "    }\n",
    ")\n",
    "\n",
    "pay = pay.withColumns(\n",
    "    {\n",
    "        'payment_sequential':col('payment_sequential').cast('int'),\n",
    "        'payment_installments':col('payment_installments').cast('int'),\n",
    "        'payment_value':col('payment_value').cast('float')\n",
    "    }\n",
    ")\n",
    "\n",
    "reviews = reviews.withColumns(\n",
    "    {\n",
    "        'review_score':col('review_score').cast('int'),\n",
    "        'review_creation_date':to_timestamp(col('review_creation_date'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType()),\n",
    "        'review_answer_timestamp':to_timestamp(col('review_answer_timestamp'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType())\n",
    "    }\n",
    ")\n",
    "\n",
    "order = order.withColumns(\n",
    "    {\n",
    "        'order_purchase_timestamp':to_timestamp(col('order_purchase_timestamp'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType()),\n",
    "        'order_approved_at':to_timestamp(col('order_approved_at'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType()),\n",
    "        'order_delivered_carrier_date':to_timestamp(col('order_delivered_carrier_date'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType()),\n",
    "        'order_delivered_customer_date':to_timestamp(col('order_delivered_customer_date'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType()),\n",
    "        'order_estimated_delivery_date':to_timestamp(col('order_estimated_delivery_date'),'yyyy-MM-dd HH:mm:ss').cast(TimestampNTZType())\n",
    "    }\n",
    ")\n",
    "\n",
    "products = products.withColumns(\n",
    "    {\n",
    "        'product_name_lenght':col('product_name_lenght').cast('int'),\n",
    "        'product_description_lenght':col('product_description_lenght').cast('int'),\n",
    "        'product_photos_qty':col('product_photos_qty').cast('int'),\n",
    "        'product_weight_g':col('product_weight_g').cast('int'),\n",
    "        'product_length_cm':col('product_length_cm').cast('int'),\n",
    "        'product_height_cm':col('product_height_cm').cast('int'),\n",
    "        'product_width_cm':col('product_width_cm').cast('int')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6017a5e8-8b73-45ad-a5c2-44ac8de7dfbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Profit Margin Estimation (Financial Enrichment)</h3>\n",
    "<h4>\uD83D\uDCA1 Business Rationale</h4>\n",
    "<p>Olist data doesn't include the product cost price, only the selling price (price) and freight (freight_value).\n",
    "By estimating margins, we can calculate profitability per order, per category, or per seller — valuable for CFO-type insights.</p>\n",
    "\n",
    "<h4>\uD83E\uDDF1 Features</h4>\n",
    "<ul>\n",
    "  <li>estimated_cost_price</li>\n",
    "  <li>profit_margin = price - estimated_cost_price - freight_value</li>\n",
    "  <li>margin_percent = profit_margin / price * 100</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c35cce-562c-40d5-94ba-10a031420aeb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Financial Enrichment"
    }
   },
   "outputs": [],
   "source": [
    "# Assume cost price is 70% of selling price\n",
    "\n",
    "order_item = order_item.withColumn('estimate_cost_price',col('price') - (col('price')*lit(0.7)))\n",
    "\n",
    "order_item = order_item.withColumn('profit_margin',col('price')-col('estimate_cost_price')-col('freight_value'))\n",
    "\n",
    "order_item = order_item.withColumn('margin_percent',(col('profit_margin')/col('price'))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34c62e66-b11b-46bd-8753-57779fdd8480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Distance Between Seller and Customer (Logistics Enrichment)</h3>\n",
    "<h4>\uD83D\uDCA1 Business Rationale</h4>\n",
    "\n",
    "<p>Delivery delays and freight costs are heavily impacted by distance.\n",
    "By deriving geographic distances, you can measure logistics efficiency, shipping cost fairness, and warehouse planning.</p>\n",
    "\n",
    "<h4>\uD83E\uDDF1 Features</h4>\n",
    "<ul>\n",
    "  <li>seller_lat, seller_lng, customer_lat, customer_lng</li>\n",
    "  <li>distance_km (using Haversine formula)</li>\n",
    "  <li>freight_per_km</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c31008-7547-481d-b507-ce5a4eb46f92",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Logistics Enrichment"
    }
   },
   "outputs": [],
   "source": [
    "# The geolocation table contains multiple entries for the same ZIP prefix, because a ZIP prefix can span multiple nearby coordinates.So, we can’t do a direct 1-to-1 join — we need to aggregate coordinates per ZIP prefix.\n",
    "\n",
    "geo_avg = geo.groupBy('geolocation_zip_code_prefix') \\\n",
    "    .agg(\n",
    "        avg('geolocation_lat').alias('geolocation_lat'),\n",
    "        avg('geolocation_lng').alias('geolocation_lng'),\n",
    "        first('geolocation_city').alias('geolocation_city'),\n",
    "        first('geolocation_state').alias('geolocation_state')\n",
    "    )\n",
    "\n",
    "# Join customer with geo_avg\n",
    "\n",
    "customer_geo = (customer.join(geo_avg, customer.customer_zip_code_prefix == geo_avg.geolocation_zip_code_prefix, 'left') \\\n",
    "    .select('customer_id','customer_city','customer_state','customer_zip_code_prefix',col('geolocation_lat').alias('customer_lat'),col('geolocation_lng').alias('customer_lng')))\n",
    "\n",
    "# Join seller with geo_avg\n",
    "\n",
    "seller_geo = (seller.join(geo_avg, seller.seller_zip_code_prefix == geo_avg.geolocation_zip_code_prefix, 'left') \\\n",
    "    .select('seller_id','seller_city','seller_state','seller_zip_code_prefix',col('geolocation_lat').alias('seller_lat'),col('geolocation_lng').alias('seller_lng')))\n",
    "\n",
    "# Compute distance\n",
    "\n",
    "order_geo = order.join(order_item,on='order_id',how='inner') \\\n",
    "    .join(customer_geo,on='customer_id',how='inner') \\\n",
    "        .join(seller_geo,on='seller_id',how='inner')\n",
    "\n",
    "# Apply the Haversine Formula\n",
    "\n",
    "def haversine(lat1,lon1,lat2,lon2):\n",
    "    if None in(lat1,lon1,lat2,lon2):\n",
    "        return None\n",
    "    try:\n",
    "        R = 6371.0\n",
    "        lat_diff = math.radians(lat2-lat1)\n",
    "        lon_diff = math.radians(lon2-lon1)\n",
    "        a = (math.sin(lat_diff/2)**2+math.cos(math.radians(lat1))*math.cos(math.radians(lat2))*math.sin(lon_diff/2)**2)\n",
    "\n",
    "        return R*2*math.atan2(math.sqrt(a),math.sqrt(1-a))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "haversine_udf = udf(haversine,FloatType())\n",
    "\n",
    "order_geo = order_geo.withColumn('distance',haversine_udf(col('seller_lat'),col('seller_lng'),col('customer_lat'),col('customer_lng')))\n",
    "\n",
    "order_geo = order_geo.withColumn('freight_per_km',expr('try_divide(freight_value,distance)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a68e0e7-2afb-404d-9a16-913366501696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Customer Segmentation (RFM Analysis)</h3>\n",
    "<h4>\uD83D\uDCA1 Business Rationale</h4>\n",
    "\n",
    "<p>Segmenting customers based on Recency, Frequency, and Monetary helps marketing and CRM teams identify:</p>\n",
    "<ul>\n",
    "  <li>Loyal customers</li>\n",
    "  <li>At-risk customers</li>\n",
    "  <li>High spenders (VIPs)</li>\n",
    "</ul>\n",
    "\n",
    "<h4>\uD83E\uDDF1 Feature(s)</h4>\n",
    "<ul>\n",
    "  <li>recency_days</li>\n",
    "  <li>frequency (# of orders)</li>\n",
    "  <li>monetary_value</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c761b9a-5558-4065-aaa4-ba7219634b42",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "RFM Analysis"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare complete order dataframe\n",
    "\n",
    "orders_whole = order.join(order_item,on=\"order_id\",how='inner')\n",
    "\n",
    "# Take out the maximum date of order purchase\n",
    "\n",
    "max_date = orders_whole.agg(max('order_purchase_timestamp')).collect()[0][0]\n",
    "\n",
    "rfm = (orders_whole.groupBy('customer_id') \\\n",
    "    .agg(\n",
    "        max('order_purchase_timestamp').alias('last_purchase_date'),\n",
    "        count('order_id').alias('frequency'),\n",
    "        sum('price').alias('monetary')\n",
    "    ) \\\n",
    "    .withColumn('recency',datediff(lit(max_date),col('last_purchase_date'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65420712-2384-4089-95d2-124b3d54e40a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Delivery Time and Delay Classification</h3>\n",
    "<h4>\uD83D\uDCA1 Business Rationale</h4>\n",
    "\n",
    "<p>Customers expect on-time delivery. You can derive delivery performance KPIs and link them to satisfaction (review scores).</p>\n",
    "\n",
    "<h4>\uD83E\uDDF1 Features</h4>\n",
    "<ul>\n",
    "  <li>delivery_time_days</li>\n",
    "  <li>delay_days</li>\n",
    "  <li>delivery_status = On-time, Early, Late</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e832f28b-d983-4f39-991b-77f79e2feeba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delivery Timings"
    }
   },
   "outputs": [],
   "source": [
    "order = order.withColumn('delivery_days',datediff(col('order_delivered_customer_date'),col('order_approved_at')))\n",
    "order = order.withColumn('delay_days',datediff(col('order_delivered_customer_date'),col('order_estimated_delivery_date')))\n",
    "order = order.withColumn('delivery_status',when(col('delay_days')>0,'delayed').when(col('delay_days')<0,'early').otherwise('on time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7c79c84-3405-4802-a5bc-00cb2e1bf841",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Review Sentiment Analysis (Text Enrichment)</h3>\n",
    "<h4>\uD83D\uDCA1 Business Rationale</h4>\n",
    "\n",
    "<p>Review comments can be turned into sentiment polarity scores, providing a more nuanced customer satisfaction metric than 1–5 star ratings.</p>\n",
    "\n",
    "<h4>\uD83E\uDDF1 Features</h4>\n",
    "<ul>\n",
    "  <li>review_sentiment ∈ [−1, 1]</li>\n",
    "  <li>sentiment_label (Positive / Neutral / Negative)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a3cfcde-084e-4e40-957a-9e2905fba410",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sentiment Analysis"
    }
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def vader_score(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    score = analyzer.polarity_scores(text)[\"compound\"]\n",
    "    return float(score)\n",
    "\n",
    "vader_udf = udf(vader_score, FloatType())\n",
    "\n",
    "reviews = reviews.withColumn(\n",
    "    \"sentiment_score\",\n",
    "    vader_udf(\"review_comment_message\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfce5f1a-a08c-4926-92f5-b35c100b2f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Seasonality and Trend Enrichment</h3>\n",
    "<h4>\uD83D\uDCA1 Business Rationale</h4>\n",
    "\n",
    "<p>E-commerce has strong monthly, quarterly, and holiday-based seasonality.\n",
    "Helps in demand forecasting and inventory planning.</p>\n",
    "\n",
    "<h4>\uD83E\uDDF1 Features</h4>\n",
    "<ul>\n",
    "  <li>order_month</li>\n",
    "  <li>order_year</li>\n",
    "  <li>order_quarter</li>\n",
    "  <li>is_holiday_season</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23135880-a4ef-464a-8583-f74d419b3fc2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Seasonality Analysis"
    }
   },
   "outputs": [],
   "source": [
    "order = order.withColumns(\n",
    "    {\n",
    "        'order_month':month(col('order_purchase_timestamp')),\n",
    "        'order_year':year(col('order_purchase_timestamp')),\n",
    "        'order_quarter':quarter(col('order_purchase_timestamp')),\n",
    "        'is_festive_season':when(col('order_month').isin(11,12,1),True).otherwise(False)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae9903a7-253a-4742-81f5-3b054caacd6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h3>Text Enrichment</h3>\n",
    "<p>Load product translation data from MongoDB into Databricks</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "551e523c-dc76-4f5f-a23b-87007e21765b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest From MongoDB"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from bson import ObjectId\n",
    "\n",
    "uri = 'mongodb+srv://soumyap569official:Soumya2001@cluster569.mh8pcc9.mongodb.net/?appName=Cluster569'\n",
    "client = MongoClient(uri,server_api=ServerApi('1'))\n",
    "db = client['olist_translation']\n",
    "collection = db['port_to_en']\n",
    "\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "    def clean_doc(doc):\n",
    "        def clean_value(v):\n",
    "            if isinstance(v,ObjectId):\n",
    "                return str(v)\n",
    "            else:\n",
    "                return v\n",
    "        return {k:clean_value(v) for k,v in doc.items()}\n",
    "    olist_trans = [clean_doc(doc) for doc in collection.find()]\n",
    "    trans_df = spark.createDataFrame(olist_trans)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0d63b51-0035-4247-893c-2aabb4896b6b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation on Ingest Data"
    }
   },
   "outputs": [],
   "source": [
    "trans_df = trans_df.drop('_id')\n",
    "products = products.join(trans_df,on='product_category_name',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7eb186d-c17c-44a0-8f72-fe970cdbaa3d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Into S3"
    }
   },
   "outputs": [],
   "source": [
    "# Customer Dataframe\n",
    "customer.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/customer/')\n",
    "\n",
    "#Customer_Geo Dataframe\n",
    "customer_geo.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/customer_geo/')\n",
    "\n",
    "#Geo Dataframe\n",
    "geo.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/geo/')\n",
    "\n",
    "#Order Item Dataframe\n",
    "order_item.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/order_item')\n",
    "\n",
    "#Complete Order Dataframe\n",
    "orders_whole.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/orders_whole')\n",
    "\n",
    "#RFM Dataframe\n",
    "rfm.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/rfm')\n",
    "\n",
    "#Order Dataframe\n",
    "order.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/order')\n",
    "\n",
    "#Order Geo Dataframe\n",
    "order_geo.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/order_geo')\n",
    "\n",
    "#Payment Dataframe\n",
    "pay.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/payment')\n",
    "\n",
    "#Seller Dataframe\n",
    "seller.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/seller')\n",
    "\n",
    "#Seller Geo Dataframe\n",
    "seller_geo.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/seller_geo')\n",
    "\n",
    "#Product Dataframe\n",
    "products.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/products')\n",
    "\n",
    "#Review Dataframe\n",
    "reviews.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/reviews')\n",
    "\n",
    "#Product Translation Dataframe\n",
    "trans_df.write \\\n",
    "    .format('parquet') \\\n",
    "        .mode('overwrite') \\\n",
    "            .save('s3://amz-s3-databricks-conn/Silver/product_with_translation')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "textblob",
     "googletrans==4.0.0rc1",
     "deep-translator",
     "transformers",
     "torch",
     "vaderSentiment",
     "pysentimiento",
     "pymongo"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Olist Ecommerce Data Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}